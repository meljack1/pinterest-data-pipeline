{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS and mount S3 drive to Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# pyspark functions \n",
    "from pyspark.sql.functions import *\n",
    "# pyspark window \n",
    "from pyspark.sql.window import Window\n",
    "# URL processing\n",
    "import urllib\n",
    "\n",
    "# Specify file type to be csv\n",
    "file_type = \"csv\"\n",
    "# Indicates file has first row as the header\n",
    "first_row_is_header = \"true\"\n",
    "# Indicates file has comma as the delimeter\n",
    "delimiter = \",\"\n",
    "# Read the CSV file to spark dataframe\n",
    "aws_keys_df = spark.read.format(file_type)\\\n",
    ".option(\"header\", first_row_is_header)\\\n",
    ".option(\"sep\", delimiter)\\\n",
    ".load(\"/FileStore/tables/authentication_credentials.csv\")\n",
    "\n",
    "# Get the AWS access key and secret key from the spark dataframe\n",
    "ACCESS_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Secret access key').collect()[0]['Secret access key']\n",
    "# Encode the secrete key\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")\n",
    "\n",
    "# AWS S3 bucket name\n",
    "AWS_S3_BUCKET = \"user-124df56aef51-bucket\"\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"/mnt/pinterest-bucket\"\n",
    "# Source url\n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "# Mount the drive in databricks\n",
    "dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load batch-processed data from S3 bucket partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "# Asterisk(*) indicates reading all the content of the specified file that have .json extension\n",
    "file_location_pin = \"/mnt/pinterest-bucket/topics/124df56aef51.pin/partition=0/*.json\" \n",
    "file_location_geo = \"/mnt/pinterest-bucket/topics/124df56aef51.geo/partition=0/*.json\" \n",
    "file_location_user = \"/mnt/pinterest-bucket/topics/124df56aef51.user/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_pin = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location_pin)\n",
    "\n",
    "df_geo = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location_geo)\n",
    "\n",
    "df_user = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location_user)\n",
    "\n",
    "# Display Spark dataframe to check its content\n",
    "display(df_pin)\n",
    "display(df_geo)\n",
    "display(df_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataframe for Pin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets multiplier for follower count (k or M)\n",
    "def get_follower_count_multiplier(df):\n",
    "    return df.withColumn(\"multiplier\",\\\n",
    "    \"1\" * \\\n",
    "    regexp_replace(\\\n",
    "        regexp_replace(\\\n",
    "            regexp_replace(col(\"follower_count\"), \"[0123456789]\", \"\"),\\\n",
    "            \"[k]\", \"1000\"),\\\n",
    "        \"[M]\", \"1000000\")\\\n",
    "    )\\\n",
    "    .na.fill(value=1,subset=[\"multiplier\"])\n",
    "\n",
    "# Converts follower count in k or M to raw number\n",
    "def follower_count_to_int(df):\n",
    "    return df.withColumn(\"follower_count\", regexp_replace(col(\"follower_count\"), \"[A-Za-z]\", \"\").cast(\"int\") * col(\"multiplier\"))\n",
    "\n",
    "# Cleans pin dataframe\n",
    "df_pin = df_pin.select([when(col(c)==\"\",None).otherwise(col(c)).alias(c) for c in df_pin.columns])\\\n",
    "    .withColumn(\"description\", when(col(\"description\")==\"No description available Story format\" ,None).otherwise(col(\"description\")))\\\n",
    "    .withColumn(\"follower_count\", when(col(\"follower_count\")==\"User Info Error\" ,None).otherwise(col(\"follower_count\")))\\\n",
    "    .transform(get_follower_count_multiplier)\\\n",
    "    .transform(follower_count_to_int)\\\n",
    "    .drop(\"multiplier\")\\\n",
    "    .withColumn(\"downloaded\", col(\"downloaded\").cast(\"int\"))\\\n",
    "    .withColumn(\"index\", col(\"index\").cast(\"int\"))\\\n",
    "    .withColumnRenamed(\"index\", \"ind\")\\\n",
    "    .withColumn(\"save_location\", regexp_replace(col(\"save_location\"), \"Local save in \", \"\"))\\\n",
    "    .withColumn(\"image_src\", when(col(\"image_src\")==\"Image src error.\" ,None).otherwise(col(\"image_src\")))\\\n",
    "    .withColumn(\"tag_list\", when(col(\"tag_list\")==\"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\" ,None).otherwise(col(\"tag_list\")))\\\n",
    "    .withColumn(\"title\", when(col(\"title\")==\"No Title Data Available\" ,None).otherwise(col(\"title\")))\n",
    "\n",
    "# Reorder pin dataframe columns\n",
    "df_pin = df_pin.select(\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\")\n",
    "\n",
    "# Display updated Spark dataframe\n",
    "display(df_pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataframe for Geo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans geographical dataframe\n",
    "df_geo = df_geo.select([when(col(c)==\"\",None).otherwise(col(c)).alias(c) for c in df_geo.columns])\\\n",
    "    .withColumn(\"coordinates\",array(col(\"latitude\"), col(\"longitude\")))\\\n",
    "    .drop(\"latitude\")\\\n",
    "    .drop(\"longitude\")\\\n",
    "    .withColumn(\"timestamp\", to_timestamp(\"timestamp\", 'MM/dd/yyyy, HH:mm:ss'))\\\n",
    "    .withColumn(\"ind\", col(\"ind\").cast(\"int\"))\n",
    "\n",
    "# Reorder geographical dataframe columns\n",
    "df_geo = df_geo.select(\"ind\", \"country\", \"coordinates\", \"timestamp\")\n",
    "\n",
    "# Display updated Spark dataframe\n",
    "display(df_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataframe for User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans user info dataframe\n",
    "df_user = df_user.select([when(col(c)==\"\",None).otherwise(col(c)).alias(c) for c in df_user.columns])\\\n",
    "    .withColumn(\"user_name\",concat_ws(\" \", col(\"first_name\"), col(\"last_name\")))\\\n",
    "    .drop(\"first_name\")\\\n",
    "    .drop(\"last_name\")\\\n",
    "    .withColumn(\"date_joined\", to_timestamp(\"date_joined\", 'MM/dd/yyyy, HH:mm:ss'))\\\n",
    "    .withColumn(\"ind\", col(\"ind\").cast(\"int\"))\\\n",
    "    .withColumn(\"age\", col(\"age\").cast(\"int\"))\n",
    "\n",
    "# Reorder user dataframe columns\n",
    "df_user = df_user.select(\"ind\", \"user_name\", \"age\", \"date_joined\")\n",
    "\n",
    "# Display updated Spark dataframe\n",
    "display(df_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions - run this before querying data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split user age into age categories\n",
    "def get_age_category(age):\n",
    "    if age < 25:\n",
    "        return \"18-24\"\n",
    "    elif age < 36:\n",
    "        return \"25-35\"\n",
    "    elif age < 51:\n",
    "        return \"36-50\"\n",
    "    elif age >= 51:\n",
    "        return \"50+\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create user defined function from get_age_category\n",
    "# https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.functions.udf.html    \n",
    "get_age_category_udf = udf(get_age_category)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Querying\n",
    "\n",
    "1. The most popular category in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_popular_category = df_geo.select(col(\"ind\"), col(\"country\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"category\")), df_geo[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .groupBy(\"country\", \"category\")\\\n",
    "    .agg(count('category').alias(\"category_count\"))\n",
    "\n",
    "# Display table ordered by country in alphabetical order\n",
    "df_most_popular_category.select(\"country\", \"category\", \"category_count\")\\\n",
    "    .groupBy(\"country\")\\\n",
    "    .agg(max(\"category\").alias(\"category\"),\\\n",
    "        max(\"category_count\").alias(\"category_count\"))\\\n",
    "    .orderBy(col(\"country\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The most popular category each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_popular_category_by_year = df_geo.select(col(\"ind\"), year(\"timestamp\").alias(\"post_year\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"category\")), df_geo[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .groupBy(\"post_year\", \"category\")\\\n",
    "    .agg(count('category').alias(\"category_count\")).orderBy(col(\"category\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The user with the most followers in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_followed_user_by_country = df_geo.select(col(\"ind\"), col(\"country\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"poster_name\"), col(\"follower_count\")), df_geo[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .groupBy(\"country\", \"poster_name\")\\\n",
    "    .agg(max(\"follower_count\").alias(\"follower_count\"))\\\n",
    "    .orderBy(col(\"country\").asc())\n",
    "\n",
    "# Display table with most followed user in each country\n",
    "display(df_most_followed_user_by_country)\n",
    "\n",
    "# Display data for only the #1 most followed user globally\n",
    "df_most_followers_country = df_most_followed_user_by_country.orderBy(col(\"follower_count\").desc()).limit(1).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The most popular category with each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get order of popularity of categories by age\n",
    "df_most_popular_category_by_age = df_user.select(col(\"ind\"), col(\"age\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"category\")), df_user[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .withColumn(\"age_group\", get_age_category_udf(col(\"age\")))\\\n",
    "    .drop(\"age\")\\\n",
    "    .groupBy(\"age_group\", \"category\")\\\n",
    "    .agg(count('category').alias(\"category_count\"))\\\n",
    "    .orderBy(col(\"category\").asc())\n",
    "\n",
    "display(df_most_popular_category_by_age)\n",
    "\n",
    "# Get only the top categories by age group\n",
    "df_most_popular_category_by_age.select(\"age_group\", \"category\", \"category_count\")\\\n",
    "    .groupBy(\"age_group\")\\\n",
    "    .agg(max(\"category_count\").alias(\"category_count\"))\\\n",
    "    .join(df_most_popular_category_by_age, on=['age_group','category_count'], how='inner')\\\n",
    "    .orderBy(col(\"age_group\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The median follower count with each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median_follower_count_by_age = df_user.select(col(\"ind\"), col(\"age\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"follower_count\")), df_user[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .withColumn(\"age_group\", get_age_category_udf(col(\"age\")))\\\n",
    "    .drop(\"age\")\\\n",
    "    .groupBy(\"age_group\")\\\n",
    "    .agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\"))\\\n",
    "    .orderBy(col(\"age_group\").asc())\n",
    "\n",
    "display(df_median_follower_count_by_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. The number of users joining each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_joined_by_year = df_user.select(col(\"ind\"), year(\"date_joined\").alias(\"year_joined\"))\\\n",
    "    .groupBy(\"year_joined\")\\\n",
    "    .agg(count(\"ind\").alias(\"number_users_joined\"))\\\n",
    "    .orderBy(col(\"year_joined\").asc())\n",
    "\n",
    "display(df_users_joined_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The median follower count of users based on their joining year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median_follower_count_by_year = df_user.select(col(\"ind\"), year(\"date_joined\").alias(\"year_joined\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"follower_count\")), df_user[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .groupBy(\"year_joined\")\\\n",
    "    .agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\"))\\\n",
    "    .orderBy(col(\"year_joined\").asc())\n",
    "\n",
    "display(df_median_follower_count_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. The median follower count of users based on their joining year and age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median_follower_count_by_age_and_year = df_user.select(col(\"ind\"), col(\"age\"), year(\"date_joined\").alias(\"year_joined\"))\\\n",
    "    .join(df_pin.select(col(\"ind\"), col(\"follower_count\")), df_user[\"ind\"] == df_pin[\"ind\"])\\\n",
    "    .drop(\"ind\")\\\n",
    "    .withColumn(\"age_group\", get_age_category_udf(col(\"age\")))\\\n",
    "    .drop(\"age\")\\\n",
    "    .groupBy(\"age_group\", \"year_joined\")\\\n",
    "    .agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\"))\\\n",
    "    .orderBy(col(\"age_group\").asc(), col(\"year_joined\").asc())\n",
    "\n",
    "display(df_median_follower_count_by_age_and_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
